# CORe-Capitalizing-On-Rewards-in-Bandit-Exploration

Demonstration codes of the paper "[CORe: Capitalizing On Rewards in Bandit Exploration](https://proceedings.mlr.press/v161/wang21c)", which is accepted to UAI'21.

We apply CORe to both multi-armed bandit and linear bandit settings and compare it with several popular baselines. 

If you find this repo useful, please cite our paper below.

    @InProceedings{pmlr-v161-wang21c,
      title = 	 {CORe: Capitalizing On Rewards in Bandit Exploration},
      author =       {Wang, Nan and Kveton, Branislav and Karimzadehgan, Maryam},
      booktitle = 	 {Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence},
      pages = 	 {1968--1978},
      year = 	 {2021},
      editor = 	 {de Campos, Cassio and Maathuis, Marloes H.},
      volume = 	 {161},
      series = 	 {Proceedings of Machine Learning Research},
      month = 	 {27--30 Jul},
      publisher =    {PMLR},
      pdf = 	 {https://proceedings.mlr.press/v161/wang21c/wang21c.pdf},
      url = 	 {https://proceedings.mlr.press/v161/wang21c.html},
    }

